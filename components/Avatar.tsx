

import React, { useEffect, useRef, useState } from 'react';
import { GoogleGenAI, Chat } from '@google/genai';
import { supabaseService, Cita } from '../services/supabase';
import { calendarService } from '../services/calendar';
import { emailService } from '../services/email';

// Token de HeyGen
const HEYGEN_API_TOKEN = "N2U3YzdmMTQyNmQzNGQ1Y2I3ZjFmY2IwOTc3ZmJiZjAtMTc0MjQ5NzY0OA=="; 
const AVATAR_ID = "Elenora_IT_Sitting_public";

// Definici√≥n de las funciones que Gemini puede llamar
const AVAILABLE_FUNCTIONS = [
    {
        name: 'agendarCita',
        description: 'Agenda una cita para el cliente. Usa esta funci√≥n cuando el usuario quiera agendar una cita, reservar, o programar una reuni√≥n.',
        parameters: {
            type: 'object',
            properties: {
                nombre: {
                    type: 'string',
                    description: 'Nombre completo del cliente'
                },
                email: {
                    type: 'string',
                    description: 'Email del cliente'
                },
                telefono: {
                    type: 'string',
                    description: 'Tel√©fono de contacto'
                },
                fecha: {
                    type: 'string',
                    description: 'Fecha de la cita en formato YYYY-MM-DD'
                },
                hora: {
                    type: 'string',
                    description: 'Hora de la cita en formato HH:MM (24h)'
                },
                motivo: {
                    type: 'string',
                    description: 'Motivo o descripci√≥n de la cita'
                }
            },
            required: ['nombre', 'email', 'telefono', 'fecha', 'hora', 'motivo']
        }
    },
    {
        name: 'darInfo',
        description: 'Proporciona informaci√≥n sobre Charlitron, servicios, horarios, etc. Usa esta funci√≥n cuando el usuario pregunte sobre la empresa, precios, servicios disponibles, horarios de atenci√≥n, etc.',
        parameters: {
            type: 'object',
            properties: {
                tipo_info: {
                    type: 'string',
                    enum: ['servicios', 'horarios', 'precios', 'contacto', 'general'],
                    description: 'Tipo de informaci√≥n solicitada'
                },
                detalles: {
                    type: 'string',
                    description: 'Detalles adicionales sobre la consulta'
                }
            },
            required: ['tipo_info']
        }
    }
];

const Avatar: React.FC = () => {
    const [isExpanded, setIsExpanded] = useState(false);
    const [isInitialized, setIsInitialized] = useState(false);
    const [statusMessage, setStatusMessage] = useState("Iniciando...");
    const [isListening, setIsListening] = useState(false);
    const [userInput, setUserInput] = useState("");
    
    const avatarRef = useRef<any>(null);
    const mediaStreamRef = useRef<MediaStream | null>(null);
    const videoRef = useRef<HTMLVideoElement>(null);
    const chatRef = useRef<Chat | null>(null);
    const recognitionRef = useRef<any>(null);
    const inputRef = useRef<HTMLInputElement>(null);

    // Configurar reconocimiento de voz
    const setupSpeechRecognition = () => {
        const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
        
        if (!SpeechRecognition) {
            console.warn('‚ö†Ô∏è Reconocimiento de voz no disponible en este navegador');
            return;
        }

        const recognition = new SpeechRecognition();
        recognition.lang = 'es-ES';
        recognition.continuous = false;
        recognition.interimResults = false;

        recognition.onstart = () => {
            setIsListening(true);
            setStatusMessage('üé§ Escuchando...');
            console.log('üé§ Escuchando...');
        };

        recognition.onresult = (event: any) => {
            const transcript = event.results[0][0].transcript;
            console.log('üë§ Usuario dijo:', transcript);
            setIsListening(false);
            
            // Enviar el mensaje a Gemini
            handleAvatarMessage({ type: 'text', text: transcript });
        };

        recognition.onerror = (event: any) => {
            console.error('Error en reconocimiento de voz:', event.error);
            setIsListening(false);
            setStatusMessage('Te escucho...');
        };

        recognition.onend = () => {
            setIsListening(false);
            if (isExpanded) {
                setStatusMessage('Te escucho...');
            }
        };

        recognitionRef.current = recognition;
    };

    // Iniciar escucha de voz
    const startListening = () => {
        if (recognitionRef.current && !isListening) {
            try {
                recognitionRef.current.start();
            } catch (error) {
                console.error('Error al iniciar reconocimiento:', error);
            }
        }
    };

    useEffect(() => {
        const startSession = async () => {
            // Verificar que StreamingAvatar est√© disponible
            if (typeof (window as any).StreamingAvatar === 'undefined') {
                console.error('‚ùå StreamingAvatar SDK no disponible');
                setStatusMessage("Error: SDK de Avatar no cargado");
                return;
            }

            const StreamingAvatar = (window as any).StreamingAvatar;

            // 1. Validar el token de HeyGen primero.
            if (!HEYGEN_API_TOKEN) {
                setStatusMessage("Falta el Token de HeyGen!");
                console.error("HEYGEN_API_TOKEN no est√° configurado");
                return;
            }

            // 2. Inicializar el cliente de Gemini AI con Function Calling.
            try {
                setStatusMessage("Conectando con IA...");
                const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
                chatRef.current = ai.chats.create({
                    model: 'gemini-2.5-flash',
                    config: {
                        systemInstruction: `Eres Elena, asistente virtual de Charlitron. 
                        
Tu rol es ayudar a los clientes de manera amigable y profesional.

INSTRUCCIONES IMPORTANTES:
- Cuando un cliente quiera agendar una cita, pregunta por: nombre, email, tel√©fono, fecha preferida, hora y motivo.
- Una vez tengas TODA la informaci√≥n, usa la funci√≥n "agendarCita".
- Si preguntan por servicios, horarios o informaci√≥n general, usa "darInfo".
- S√© conversacional, c√°lida y eficiente.
- Habla en espa√±ol de forma natural.
- Mant√©n respuestas concisas (2-3 oraciones m√°ximo).

INFORMACI√ìN DE CHARLITRON:
- Servicios: Desarrollo web, apps m√≥viles, consultor√≠a IA, automatizaci√≥n
- Horario: Lunes a Viernes 9:00-18:00
- Ubicaci√≥n: Ciudad de M√©xico
- Email: contacto@charlitron.com
- Tel√©fono: +52 55 1234 5678`,
                        tools: AVAILABLE_FUNCTIONS as any,
                    },
                });
                console.log('‚úÖ Gemini inicializado con Function Calling');
            } catch (error) {
                console.error("Error al inicializar Gemini:", error);
                setStatusMessage("Error al conectar con IA.");
                return;
            }

            // 3. Inicializar el Avatar de HeyGen.
            try {
                setStatusMessage("Solicitando permisos...");
                mediaStreamRef.current = await navigator.mediaDevices.getUserMedia({ audio: true });

                setStatusMessage("Conectando con el avatar...");
                
                // Obtener la clase StreamingAvatar del objeto window
                const StreamingAvatar = (window as any).StreamingAvatar;
                
                const avatar = new StreamingAvatar({
                    token: HEYGEN_API_TOKEN,
                    avatarId: AVATAR_ID,
                });
                avatarRef.current = avatar;

                avatar.on('session.message', handleAvatarMessage);
                avatar.on('session.start', () => {
                    setStatusMessage('¬°Haz clic y habla conmigo!');
                    setIsInitialized(true);
                    
                    // Inicializar reconocimiento de voz
                    setupSpeechRecognition();
                });
                avatar.on('session.close', () => {
                    setStatusMessage('Sesi√≥n terminada. Haz clic para reiniciar.');
                    setIsInitialized(false);
                });
                avatar.on('session.error', (error) => {
                    console.error('Error en la sesi√≥n del avatar:', error);
                    setStatusMessage(`Error. Refresca la p√°gina.`);
                });
                avatar.on('media.stream', (stream: MediaStream) => {
                    if (videoRef.current) {
                        videoRef.current.srcObject = stream;
                    }
                });
                
                // FIX: Corrected method 'startSession' to 'start'. 'startSession' expects 0 arguments, but the media stream needs to be passed.
                await avatar.start({ mediaStream: mediaStreamRef.current });
            } catch (err: any) {
                console.error('Fallo al inicializar el avatar:', err);
                if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                    setStatusMessage('Permiso de micr√≥fono denegado.');
                } else {
                    setStatusMessage('Error al iniciar el avatar.');
                }
            }
        };

        startSession();

        return () => {
            // FIX: Corrected method 'stopSession' to 'stop' as 'stopSession' does not exist on type 'StreamingAvatar'.
            avatarRef.current?.stop();
            mediaStreamRef.current?.getTracks().forEach(track => track.stop());
        };
    }, []);

    const handleAvatarMessage = async (message: { type: string, text: string }) => {
        if (message.type === 'text' && message.text.trim() && chatRef.current) {
            setStatusMessage("Pensando...");
            console.log('üë§ Usuario:', message.text);
            
            try {
                const stream = await chatRef.current.sendMessageStream({ message: message.text });
                
                let fullResponse = '';
                let functionCalls: any[] = [];
                
                // Procesar el stream de respuesta
                for await (const chunk of stream) {
                    // Si hay texto, acumularlo
                    if (chunk.text) {
                        fullResponse += chunk.text;
                    }
                    
                    // Si hay function calls, guardarlos
                    if (chunk.functionCalls && chunk.functionCalls.length > 0) {
                        functionCalls = chunk.functionCalls;
                    }
                }

                console.log('ü§ñ Respuesta completa:', fullResponse);
                console.log('üîß Function calls:', functionCalls);

                // Si hay function calls, ejecutarlos
                if (functionCalls.length > 0) {
                    await processFunctionCalls(functionCalls);
                } else if (fullResponse) {
                    // Si solo hay texto, hacer que el avatar hable
                    setStatusMessage("Elena est√° hablando...");
                    await avatarRef.current?.speak({ text: fullResponse });
                    setStatusMessage('Te escucho...');
                }

            } catch (error) {
                console.error("Error con la API de Gemini:", error);
                setStatusMessage("Lo siento, ocurri√≥ un error.");
                await avatarRef.current?.speak({ text: "Estoy teniendo un peque√±o problema ahora mismo. ¬øPuedes repetir?" });
                setStatusMessage('Te escucho...');
            }
        }
    };

    /**
     * Procesa los Function Calls de Gemini y ejecuta las acciones correspondientes
     */
    const processFunctionCalls = async (functionCalls: any[]) => {
        for (const call of functionCalls) {
            const functionName = call.name;
            const args = call.args;

            console.log(`üîß Ejecutando funci√≥n: ${functionName}`, args);
            setStatusMessage(`Ejecutando: ${functionName}...`);

            let result: any;

            try {
                if (functionName === 'agendarCita') {
                    result = await ejecutarAgendarCita(args);
                } else if (functionName === 'darInfo') {
                    result = await ejecutarDarInfo(args);
                } else {
                    result = { success: false, message: 'Funci√≥n no reconocida' };
                }

                console.log(`‚úÖ Resultado de ${functionName}:`, result);

                // Enviar el resultado de vuelta a Gemini para que genere una respuesta natural
                const followUpStream = await chatRef.current!.sendMessageStream({
                    message: `Resultado de la funci√≥n ${functionName}: ${JSON.stringify(result)}`
                });

                let responseText = '';
                for await (const chunk of followUpStream) {
                    if (chunk.text) {
                        responseText += chunk.text;
                    }
                }

                // Hacer que el avatar hable la respuesta
                if (responseText) {
                    setStatusMessage("Elena est√° hablando...");
                    await avatarRef.current?.speak({ text: responseText });
                }

            } catch (error: any) {
                console.error(`Error ejecutando ${functionName}:`, error);
                await avatarRef.current?.speak({ 
                    text: `Lo siento, tuve un problema al ${functionName === 'agendarCita' ? 'agendar la cita' : 'obtener la informaci√≥n'}.` 
                });
            }
        }
        
        setStatusMessage('Te escucho...');
    };

    /**
     * Ejecuta la funci√≥n de agendar cita
     */
    const ejecutarAgendarCita = async (args: any): Promise<any> => {
        const citaData: Cita = {
            nombre: args.nombre,
            email: args.email,
            telefono: args.telefono,
            fecha: args.fecha,
            hora: args.hora,
            motivo: args.motivo
        };

        console.log('üìÖ Agendando cita:', citaData);

        // 1. Guardar en Supabase
        const dbResult = await supabaseService.guardarCita(citaData);
        
        // 2. Crear evento en Google Calendar (mock por ahora)
        const calendarResult = await calendarService.crearEvento({
            nombre: citaData.nombre,
            email: citaData.email,
            fecha: citaData.fecha,
            hora: citaData.hora,
            motivo: citaData.motivo
        });

        // 3. Enviar email de confirmaci√≥n (mock por ahora)
        const emailResult = await emailService.enviarConfirmacionCita({
            to: citaData.email,
            subject: '‚úÖ Cita confirmada - Charlitron',
            nombre: citaData.nombre,
            fecha: citaData.fecha,
            hora: citaData.hora,
            motivo: citaData.motivo
        });

        return {
            success: true,
            message: `Cita agendada para ${citaData.nombre} el ${citaData.fecha} a las ${citaData.hora}`,
            detalles: {
                base_datos: dbResult.message,
                calendario: calendarResult.message,
                email: emailResult.message
            }
        };
    };

    /**
     * Ejecuta la funci√≥n de dar informaci√≥n
     */
    const ejecutarDarInfo = async (args: any): Promise<any> => {
        const { tipo_info, detalles } = args;

        console.log(`‚ÑπÔ∏è Solicitando info de tipo: ${tipo_info}`, detalles);

        // Base de conocimiento
        const infoBase: any = {
            servicios: {
                titulo: 'Nuestros Servicios',
                contenido: `Ofrecemos:
- üåê Desarrollo Web (React, Next.js, TypeScript)
- üì± Apps M√≥viles (iOS/Android)
- ü§ñ Soluciones de IA y Machine Learning
- ‚ö° Automatizaci√≥n de procesos
- üíº Consultor√≠a tecnol√≥gica`
            },
            horarios: {
                titulo: 'Horarios de Atenci√≥n',
                contenido: 'Lunes a Viernes de 9:00 a 18:00 hrs. S√°bados de 10:00 a 14:00 hrs.'
            },
            precios: {
                titulo: 'Informaci√≥n de Precios',
                contenido: 'Nuestros precios var√≠an seg√∫n el proyecto. Agenda una consulta gratuita para recibir una cotizaci√≥n personalizada.'
            },
            contacto: {
                titulo: 'Contacto',
                contenido: `üìß Email: contacto@charlitron.com
üì± Tel√©fono: +52 55 1234 5678
üìç Ubicaci√≥n: Ciudad de M√©xico
üåê Web: www.charlitron.com`
            },
            general: {
                titulo: 'Sobre Charlitron',
                contenido: 'Somos una empresa de tecnolog√≠a especializada en desarrollo de software y soluciones de IA. Ayudamos a empresas a transformarse digitalmente.'
            }
        };

        const info = infoBase[tipo_info] || infoBase.general;

        // Guardar la consulta en Supabase (opcional)
        await supabaseService.guardarConsulta({
            pregunta: detalles || tipo_info,
            respuesta: info.contenido
        });

        return {
            success: true,
            tipo: tipo_info,
            informacion: info.contenido
        };
    };

    const handleContainerClick = () => {
        if (!isExpanded) {
            // Expandir
            setIsExpanded(true);
            // Iniciar escucha autom√°ticamente
            setTimeout(() => startListening(), 500);
        } else {
            // Si est√° expandido y no est√° escuchando, iniciar escucha
            if (!isListening) {
                startListening();
            }
        }
        
        // Reiniciar sesi√≥n si est√° cerrada
        if (avatarRef.current?.state === 'closed' && mediaStreamRef.current) {
             avatarRef.current.start({ mediaStream: mediaStreamRef.current });
        }
    };
    
    // Enviar mensaje por texto
    const handleSendMessage = (e?: React.FormEvent) => {
        e?.preventDefault();
        if (userInput.trim() && chatRef.current) {
            const message = userInput.trim();
            setUserInput("");
            handleAvatarMessage({ type: 'text', text: message });
        }
    };

    const containerClasses = [
        'show',
        isInitialized ? 'initialized' : '',
        isExpanded ? 'expand' : '',
        isListening ? 'listening' : ''
    ].join(' ');

    return (
        <div id="avatar-container" className={containerClasses} onClick={(e) => {
            // Solo expandir si se hace clic en el contenedor, no en el input
            if (e.target === e.currentTarget || (e.target as HTMLElement).id === 'avatar-video' || (e.target as HTMLElement).id === 'avatar-overlay') {
                handleContainerClick();
            }
        }}>
            <div id="avatar-overlay">
                <span>{statusMessage}</span>
                {isListening && <div style={{marginTop: '10px', fontSize: '2em'}}>üé§</div>}
            </div>
            <video ref={videoRef} autoPlay playsInline muted id="avatar-video" />
            
            {isExpanded && isInitialized && (
                <div style={{
                    position: 'absolute',
                    bottom: '10px',
                    left: '10px',
                    right: '10px',
                    display: 'flex',
                    gap: '8px',
                    zIndex: 10,
                    pointerEvents: 'auto'
                }} onClick={(e) => e.stopPropagation()}>
                    <input
                        ref={inputRef}
                        type="text"
                        value={userInput}
                        onChange={(e) => setUserInput(e.target.value)}
                        onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                        placeholder="Escribe tu mensaje o haz clic en üé§..."
                        style={{
                            flex: 1,
                            padding: '12px',
                            borderRadius: '8px',
                            border: '2px solid #667eea',
                            fontSize: '14px',
                            outline: 'none'
                        }}
                    />
                    <button
                        onClick={handleSendMessage}
                        style={{
                            padding: '12px 20px',
                            background: '#667eea',
                            color: 'white',
                            border: 'none',
                            borderRadius: '8px',
                            cursor: 'pointer',
                            fontWeight: 'bold'
                        }}
                    >
                        Enviar
                    </button>
                    {recognitionRef.current && (
                        <button
                            onClick={(e) => {
                                e.stopPropagation();
                                startListening();
                            }}
                            disabled={isListening}
                            style={{
                                padding: '12px 20px',
                                background: isListening ? '#ccc' : '#764ba2',
                                color: 'white',
                                border: 'none',
                                borderRadius: '8px',
                                cursor: isListening ? 'not-allowed' : 'pointer',
                                fontSize: '18px'
                            }}
                        >
                            {isListening ? '‚è∏Ô∏è' : 'üé§'}
                        </button>
                    )}
                </div>
            )}
        </div>
    );
};

export default Avatar;
